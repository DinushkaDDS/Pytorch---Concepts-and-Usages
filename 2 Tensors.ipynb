{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors in Pytorch\n",
    "\n",
    "This is the main multidimensional data structure used in pytorch to do its calculations. Even though pytorch supports numpy arrays they are not suitable for deep learning related works due to multiple problems. Tensors fix those problems by providing additional features such as distributed operations on multiple devices/machines, GPU operations support, computation graph support etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((3, 2))  # Similar to numpy ones create a vector with 1 value to the given dimension.\n",
    "a[2]  # We can access elements just as we access them in numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like numpy, torch tensors are saved in memory as contiguous memory chunks. Which basically means CPU caching techniques, parrallel processing techniques can be applied easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.tensor([1,2,3,4,5,6,7,8,9])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "points_2d[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d.shape # Just like numpy XD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that, all the indexing operations return a tensor object. But it does not mean torch creates a new tensor object for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d[1,1] # Indexing the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below includes example slicing operations for tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d[1: , 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d[None] # This is special, \n",
    "                    # it adds additional dimension around the data. \n",
    "                    # Similar to the `unsqueeze` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4],\n",
       "         [5, 6]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unsqueeze(points_2d, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In torch we can give names to the the tensor dimensions(Experimental feature!). This is helpful in keeping track of dimensions throughout complex operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = torch.rand((3, 25, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ddsdi\\.virtualenvs\\Pytorch_-_Use_Case_Exploration-FSDBtUdB\\lib\\site-packages\\torch\\_tensor.py:905: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10/core/TensorImpl.h:1408.)\n",
      "  return super(Tensor, self).refine_names(names)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5485, 0.5179, 0.3718,  ..., 0.3386, 0.7032, 0.0538],\n",
       "         [0.8161, 0.4748, 0.1484,  ..., 0.2440, 0.2855, 0.6904],\n",
       "         [0.8604, 0.7152, 0.5117,  ..., 0.4493, 0.3384, 0.6642],\n",
       "         ...,\n",
       "         [0.0402, 0.8522, 0.2582,  ..., 0.3640, 0.1131, 0.1111],\n",
       "         [0.4787, 0.3820, 0.9931,  ..., 0.5017, 0.7539, 0.1426],\n",
       "         [0.4462, 0.0910, 0.1155,  ..., 0.6020, 0.9075, 0.0931]],\n",
       "\n",
       "        [[0.5188, 0.7891, 0.9740,  ..., 0.3745, 0.2788, 0.7585],\n",
       "         [0.1483, 0.9685, 0.5006,  ..., 0.8362, 0.0375, 0.1448],\n",
       "         [0.7215, 0.0814, 0.7408,  ..., 0.5229, 0.2238, 0.3893],\n",
       "         ...,\n",
       "         [0.8274, 0.1469, 0.4439,  ..., 0.6575, 0.4228, 0.7071],\n",
       "         [0.3851, 0.8331, 0.9895,  ..., 0.6077, 0.5968, 0.5964],\n",
       "         [0.3364, 0.1816, 0.0257,  ..., 0.9907, 0.1269, 0.1198]],\n",
       "\n",
       "        [[0.4230, 0.3410, 0.4444,  ..., 0.2268, 0.0655, 0.3102],\n",
       "         [0.7054, 0.6552, 0.7055,  ..., 0.6521, 0.8026, 0.0387],\n",
       "         [0.9557, 0.2813, 0.8386,  ..., 0.5676, 0.3350, 0.6215],\n",
       "         ...,\n",
       "         [0.3910, 0.4216, 0.0971,  ..., 0.3674, 0.6338, 0.9114],\n",
       "         [0.1725, 0.9180, 0.8769,  ..., 0.8817, 0.9200, 0.8566],\n",
       "         [0.0255, 0.6748, 0.8937,  ..., 0.8739, 0.7717, 0.0778]]],\n",
       "       names=('Channel', 'Height', 'Width'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.refine_names(..., 'Channel', 'Height', 'Width')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python standard data types are not optimal for large numerical operations. \n",
    "\n",
    "1. They are objects.\n",
    "2. Python lists are collections of objects which does not have contigious memory allocation.\n",
    "3. Python interpreter is not optimal compared to more specialized compiled code.\n",
    "\n",
    "Therefore just as numpy, cython torch tensors use ctype data or more efficient low level numerical data structures.\n",
    "\n",
    "In tensor constructor we can pass the datatype using `dtype` parameter. Some of the possible values are as below.\n",
    "\n",
    "* torch.float (float32)\n",
    "* torch.double (float64)\n",
    "* torch.int8\n",
    "* torch.uint8\n",
    "* torch.int\n",
    "* torch.long (int64)\n",
    "* torch.bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((5,5), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((5,5)).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((5,5)).to(torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details about the pytorch tensor usage refer the [documentation](http://pytorch.org/docs).\n",
    "\n",
    "But as a general overview how tensors work under the hood is as follows.\n",
    "\n",
    "- Theres a torch class named `torch.Storage`. This is a one dimensional array of numerical data type spread over a contigious memory space.\n",
    "- Tensors are a type of view which utilizes this one dimensional data structure in a clever manner to provide fast and efficient indexes. (The indexing mechanism is kinda similar to how we can store a binary tree in a list.)\n",
    "\n",
    "Because of that, underline memory is allocated once. But we can index, reshape very fast since we are only using views on top of actual data. Very Cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6\n",
       "[torch.storage._TypedStorage(dtype=torch.int64, device=cpu) of size 6]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d.storage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other than the details regarding storage, tensors need few more details to provide the views to data like size, offset, stride. These are called metadata(obviously). By using these metadata, tensors can provide the view upon the `storage` data structure in various patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_2d.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor([i for i in range(1000)])\n",
    "x = t.reshape((10,10,10))\n",
    "print(x.stride())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point to note is that, some storage objects may not be contiguous. And this may cause problems as some pytorch operations require to have contiguous tensors. To fix that issue we can use `contiguous` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([i for i in range(6)]).reshape((2,3))\n",
    "t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_t = t.t()\n",
    "t_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]]) stride (1, 3) offset 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"{t_t} stride {t_t.stride()} offset {t_t.storage_offset()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t_t.contiguous()\n",
    "x.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch allows us to process data directly on GPU (CUDA supported). This can be done during the initial creation of the tensor or we can later copy a tensor made for cpu processing to GPU processing. Doing so returns a tensor that has the same numerical data, but stored in the RAM of the GPU, rather than in regular system RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "point2d_gpu = torch.tensor([[1, 2],\n",
    "                            [3, 4],\n",
    "                            [5, 6]], device='cuda')\n",
    "point2d_gpu = points_2d.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 5],\n",
       "        [2, 4, 6]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point2d_gpu.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to move back the tensor from GPU to CPU we need to move using `to` function.\n",
    "\n",
    "> Another note about tensors is we can convert them to numpy easily by using `numpy` function or from numpy array to tensor by `from_numpy` function.\n",
    "\n",
    "\n",
    "We can save tensors to load in some another point by serializing it to the disk as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(points_2d, \"tensors/points2d.t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_points = torch.load(\"tensors/points2d.t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the problem is tensors saved in above method is only usable from pytorch. To use tensors with other programs/libraries we can use HDF5 format. To do that using pytorch we need to have `h5py` library in our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "f = h5py.File('tensors/points2d.hdf5', 'w')\n",
    "dset = f.create_dataset('coords', data=points_2d.numpy())\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]]) [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('tensors/points2d.hdf5', 'r')\n",
    "new_points = f['coords']\n",
    "last_points = new_points[:]\n",
    "\n",
    "print(points_2d, last_points)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But usage seems bit weird tbh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Pytorch_-_Use_Case_Exploration-FSDBtUdB')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1153c933a691d5b7872e50b0da6113c7d23c17547b77ca34e6f51a7318bb0ae8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
